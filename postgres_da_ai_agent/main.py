import os
import dotenv
import argparse
from postgres_da_ai_agent.modules.db import PostgresDB
from postgres_da_ai_agent.modules import llm
from autogen import (
    AssistantAgent,
    UserProxyAgent,
    GroupChat,
    GroupChatManager,
    config_list_from_json,
    config_list_from_models,
)


dotenv.load_dotenv()

assert os.environ.get(
    "DATABASE_URL"), "POSTGRES_CONNECTION_URL not found in .env file"
assert os.environ.get(
    "OPENAI_API_KEY"), "OPENAI_API_KEY not found in .env file"

DB_URL = os.environ.get("DATABASE_URL")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

POSTGRES_TABLE_DEFINITIONS_CAP_REF = "TABLE_DEFINITIONS"
TABLE_RESPONSE_FORMAT_CAP_REF = "TABLE_RESPONSE_FORMAT"

SQL_QUERY_DELIMITER = '-----------'
AGENT_RESULT_DELIMITER = '-------- AGENT RESULT --------'


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--prompt", help="The prompt for the AI model")
    args = parser.parse_args()

    with PostgresDB() as db:
        db.connect_with_url(DB_URL)
        table_definitions = db.get_table_definitions_for_prompt()

    prompt = args.prompt

    prompt = llm.add_cap_ref(
        prompt,
        f"Use this {POSTGRES_TABLE_DEFINITIONS_CAP_REF} to satisfy the database query.",
        POSTGRES_TABLE_DEFINITIONS_CAP_REF,
        table_definitions,
    )

    # build the gpt_configuration object
    
    # build the function map
    
    # create our terminate msg function
    
    # create a set of agents with specific roles
        # - admin user proxy agent - takes the prompt and manages the group chat
        # - data engineer agent - generates the user query
        # - sr data analyst agent - run the sql query generated by the data engineer agent
        # - product manager - validate the response to make sure it is correct
    
    # create a group chat and initiate the chat


if __name__ == "__main__":
    main()
